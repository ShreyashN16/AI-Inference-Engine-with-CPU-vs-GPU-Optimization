# AI-Inference-Engine-with-CPU-vs-GPU-Optimization
Engineered a CPU vs GPU AI inference benchmarking framework comparing latency, throughput, and memory efficiency across PyTorch and ONNX Runtime with quantization and mixed precision optimizations.
